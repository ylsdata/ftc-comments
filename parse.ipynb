{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load spreadsheet and initialize result file\n",
    "df = pd.read_excel('data.xlsx', engine='openpyxl')\n",
    "RESULTS = []\n",
    "RESULTS.append(['Document ID', \n",
    "                'Total Links',\n",
    "                'Link',\n",
    "                'Download Path',\n",
    "                'Status',\n",
    "                'Code'])\n",
    "RESULTS_FILE = 'results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Specify the column with the links\n",
    "links_column = 'Attachment Files'\n",
    "id_column = 'Document ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a folder to save the downloaded files\n",
    "download_folder = Path('downloads')\n",
    "download_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Function to get the file extension from the URL or headers\n",
    "def get_file_extension(url, response):\n",
    "    # Try to extract from the URL\n",
    "    path = urlsplit(url).path\n",
    "    extension = Path(path).suffix\n",
    "    if extension:\n",
    "        return extension\n",
    "    # Fall back to the content-type header\n",
    "    content_type = response.headers.get('Content-Type')\n",
    "    if content_type:\n",
    "        return f'.{content_type.split(\"/\")[-1]}'\n",
    "    return '.bin'  # Default to .bin if no extension is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Download files from the links\n",
    "for index, links in enumerate(df[links_column]):\n",
    "    if pd.notna(links):\n",
    "        link_list = [link.strip() for link in links.split(',')]  # Split the links and remove any leading/trailing whitespace\n",
    "        for link_index, link in enumerate(link_list):\n",
    "            n_docs = len(link_list)\n",
    "            try:\n",
    "                response = requests.get(link)\n",
    "                if response.status_code == 200:\n",
    "                    extension = get_file_extension(link, response)\n",
    "                    name = df[id_column].iloc[index]\n",
    "                    file_name = download_folder / f'{name}_{link_index + 1}{extension}'\n",
    "                    with open(file_name, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    print(f'Downloaded: {file_name}')\n",
    "                    status = 'Success'\n",
    "                    RESULTS.append([df[id_column].iloc[index], n_docs, link_index, file_name, status, ''])\n",
    "                else:\n",
    "                    print(f'Failed to download {link}: Status code {response.status_code}')\n",
    "                    status = 'Failed'\n",
    "                    RESULTS.append([df[id_column].iloc[index], n_docs, link_index, file_name, status, response.status_code])\n",
    "            except Exception as e:\n",
    "                print(f'Error downloading {link}: {e}')\n",
    "                status = 'Error'\n",
    "                RESULTS.append([df[id_column].iloc[index], n_docs, link_index, file_name, status, ''])\n",
    "\n",
    "            time.sleep(10)\n",
    "    else:\n",
    "        n_docs = 0\n",
    "        print(f'Skipping row {index}: No link found')\n",
    "        status = 'Skipped'\n",
    "        RESULTS.append([df[id_column].iloc[index], n_docs, link_index, file_name, status, response.status_code])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert scrape results to data frame to verify success\n",
    "df_results = pd.DataFrame(RESULTS, columns=RESULTS[0])\n",
    "df_results.to_csv(RESULTS_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
